# ä¸»ç¨‹åº

import os
from datetime import datetime
from typing import List, Any, Dict

import ollama
import sys

from akshare_tools import *

# --- é…ç½® ---
DB_NAME = 'ollama_financial_agent.db'
MODEL_NAME = 'gpt-oss:20b'


# --- æ—¥å¿—é…ç½®ä¿®æ”¹ ---
LOG_DIR = 'debug'
LOG_FILENAME = datetime.now().strftime(f'{LOG_DIR}/%Y%m%d_%H%M%S.log')

if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR)
logging.basicConfig(level=logging.NOTSET, handlers=[])
formatter = logging.Formatter(
    '[%(asctime)s] - %(name)s - %(levelname)s - %(message)s'
)

file_handler = logging.FileHandler(LOG_FILENAME, encoding='utf-8')
file_handler.setLevel(logging.DEBUG)  # æ–‡ä»¶ä¸­è®°å½•æ‰€æœ‰ç»†èŠ‚
file_handler.setFormatter(formatter)
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.FATAL)
console_handler.setFormatter(logging.Formatter('[%(levelname)s] %(message)s'))

root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)
root_logger.addHandler(file_handler)
root_logger.addHandler(console_handler)

# è®¾ç½®æˆ‘ä»¬è‡ªå·±çš„ logger å®ä¾‹
logger = logging.getLogger(__name__)

logger.info(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚è¯¦ç»†æ—¥å¿—å·²å†™å…¥ï¼š{LOG_FILENAME}")

# è¿™ä¸ªç³»ç»Ÿæç¤ºå‘Šè¯‰ LLM å®ƒå¯ä»¥è°ƒç”¨å“ªäº›å‡½æ•°ä»¥åŠå®ƒä»¬çš„ JSON æè¿°
TOOL_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "get_stock_zh_a_spot_data",
            "description": "è·å– A è‚¡çš„å†å²è¡Œæƒ…æ•°æ®ï¼Œå¹¶å°†æ•°æ®å­˜å…¥ SQLite æ•°æ®åº“çš„å›ºå®šè¡¨ä¸­ã€‚è¿”å›åŒ…å«æœ€æ–°ä»·æ ¼çš„æ‘˜è¦ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "symbol": {"type": "string", "description": "è‚¡ç¥¨ä»£ç æˆ–æŒ‡æ•°ä»£ç ï¼Œå¦‚ '600519' æˆ– 'sh000001'"},
                    "period": {"type": "string", "description": "æ•°æ®å‘¨æœŸ ('daily', 'weekly', 'monthly')"},
                    "start_date": {"type": "string", "description": "å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'"},
                    "end_date": {"type": "string", "description": "ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD'"}
                },
                "required": ["symbol"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "visualize_stock_data_trend",
            "description": "ä»æ•°æ®åº“ä¸­è¯»å–å›ºå®šè¡¨ä¸­çš„æ•°æ®ï¼Œè®¡ç®—æ»‘åŠ¨å¹³å‡çº¿ï¼Œç”Ÿæˆå¹¶æ˜¾ç¤ºä»·æ ¼è¶‹åŠ¿å›¾ã€‚ç”¨äºå“åº”'ç”»å›¾'ã€'èµ°åŠ¿å›¾'ç­‰è¯·æ±‚ã€‚æ³¨æ„ï¼šæ­¤å·¥å…·éœ€åœ¨'get_stock_zh_a_spot_data'è°ƒç”¨åä½¿ç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "symbol": {"type": "string", "description": "è‚¡ç¥¨ä»£ç ï¼Œä»…ç”¨äºå›¾è¡¨æ ‡é¢˜ã€‚"}
                },
                "required": ["symbol"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "query_macro_data",
            "description": "æŸ¥è¯¢ä¸­å›½çš„å¹´åº¦å®è§‚ç»æµæ•°æ®ï¼Œå¦‚ CPI æˆ– GDPã€‚ç”¨äºå“åº”'æœ€æ–°CPI'ã€'GDPæ•°æ®'ç­‰è¯·æ±‚ã€‚æ•°æ®æ¥è‡ª AkShareã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "indicator": {
                        "type": "string",
                        "description": "è¦æŸ¥è¯¢çš„å®è§‚ç»æµæŒ‡æ ‡ï¼Œç›®å‰ä»…æ”¯æŒ 'CPI' (å¹´åº¦) æˆ– 'GDP' (å¹´åº¦)ã€‚",
                        "enum": ["CPI", "GDP"]
                    }
                },
                "required": ["indicator"]
            }
        }
    }
]

tool_schema_str = json.dumps(TOOL_SCHEMA, indent=2)

SYSTEM_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ•°æ®åˆ†ææ™ºèƒ½ä½“ (Agent)ã€‚ä½ çš„æ ¸å¿ƒèŒè´£æ˜¯å‡†ç¡®è°ƒç”¨å·¥å…·è·å–æ•°æ®å¹¶è¿›è¡Œåˆ†æã€‚

### ğŸš¨ æ ¸å¿ƒåŸåˆ™ (Critical Rules)
1. **ç¦æ­¢çŒœæµ‹æ•°æ®ï¼š** ä»»ä½•æ¶‰åŠè‚¡ç¥¨ä»·æ ¼ã€å†å²è¡Œæƒ…ã€è´¢åŠ¡æ•°æ®çš„è¯·æ±‚ï¼Œ**å¿…é¡»**é€šè¿‡è°ƒç”¨å·¥å…·è·å–ï¼Œä¸¥ç¦æ ¹æ®è®­ç»ƒæ•°æ®ç¼–é€ ã€‚
2. **ç›´æ¥å‡½æ•°è°ƒç”¨ï¼š** - ä¸¥ç¦åˆ›é€ ä¸å­˜åœ¨çš„å‡½æ•°ï¼ˆå¦‚ `assistant`, `call_tool`, `api_caller` ç­‰ï¼‰ã€‚
   - **ç›´æ¥ä½¿ç”¨**å·¥å…·åˆ—è¡¨ä¸­å®šä¹‰çš„å‡½æ•°åï¼ˆå¦‚ `get_stock_zh_a_spot_data`ï¼‰ã€‚
3. **å‚æ•°ç²¾ç¡®åŒ¹é…ï¼š** ä¸¥æ ¼éµå®ˆå·¥å…·å®šä¹‰ä¸­çš„å‚æ•°åå’Œæ—¥æœŸæ ¼å¼ï¼ˆé€šå¸¸ä¸º "YYYY-MM-DD"ï¼‰ã€‚

### ğŸ“ è°ƒç”¨èŒƒä¾‹ (Few-Shot Examples)

**æ­£ç¡®ç¤ºèŒƒ (Correct):**
ç”¨æˆ·: "å¸®æˆ‘æŸ¥ä¸€ä¸‹èŒ…å°(600519)æœ€è¿‘çš„è¡Œæƒ…"
æ¨¡å‹è¡Œä¸º: è°ƒç”¨å‡½æ•° `get_stock_zh_a_spot_data`
å‚æ•°: {{"symbol": "600519"}}

**é”™è¯¯ç¤ºèŒƒ (Wrong - ä¸è¦è¿™æ ·åš):**
âŒ é”™è¯¯ 1 (åµŒå¥—è°ƒç”¨): {{"function": {{"name": "assistant", "arguments": {{"tool": "get_stock_zh_a_spot_data", ...}}}}}}
âŒ é”™è¯¯ 2 (é”™è¯¯çš„å‡½æ•°å): è°ƒç”¨ `search_stock` (å¦‚æœå·¥å…·è¡¨ä¸­æ²¡æœ‰è¿™ä¸ªå‡½æ•°)

### ğŸ› ï¸ å¯ç”¨å·¥å…·å®šä¹‰ (Tool Definitions)
ä»¥ä¸‹æ˜¯ä½ å”¯ä¸€å…è®¸ä½¿ç”¨çš„å·¥å…·ï¼š

{}

---
è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œä¸€æ­¥æ­¥æ€è€ƒï¼Œå¦‚æœéœ€è¦æ•°æ®ï¼Œç«‹å³ç”Ÿæˆ Tool Callã€‚
"""
SYSTEM_PROMPT = SYSTEM_PROMPT_TEMPLATE.format(tool_schema_str)# æ‹¼åˆSYSTEM_PROMPT_TEMPLATEä¸TOOL_SCHEMA


def init_db():  # åˆå§‹åŒ–æ•°æ®åº“
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute("""
                   CREATE TABLE IF NOT EXISTS conversation
                   (
                       id
                       INTEGER
                       PRIMARY
                       KEY
                       AUTOINCREMENT,
                       role
                       TEXT
                       NOT
                       NULL,
                       content
                       TEXT
                       NOT
                       NULL,
                       timestamp
                       DATETIME
                       DEFAULT
                       CURRENT_TIMESTAMP
                   )
                   """)
    conn.commit()
    conn.close()
    logger.info(f"SQLite æ•°æ®åº“ '{DB_NAME}' åˆå§‹åŒ–å®Œæˆ.")


def save_message(role, content):
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO conversation (role, content) VALUES (?, ?)",
        (role, content)
    )
    conn.commit()
    conn.close()
    logger.info(f"æ¶ˆæ¯å·²ä¿å­˜: Role='{role}' | Content Length={len(content)}")


def load_context():
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute("SELECT role, content FROM conversation ORDER BY timestamp ASC")
    history_records = cursor.fetchall()
    conn.close()

    messages = []
    # å†å²è®°å½•ä¸­çš„ assistant æ¶ˆæ¯å¯èƒ½æ˜¯ Tool Call æˆ–æ™®é€šå“åº”ï¼Œéƒ½éœ€è¦ä¿æŒ
    for role, content in history_records:
        messages.append({'role': role, 'content': content})

    logger.info(f"å·²åŠ è½½ {len(messages)} æ¡å†å²æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡.")
    return messages


def clear_screen():
    os.system('cls')


# Tool Calling è§£æä¸æ‰§è¡Œ
# åå°„
def execute_single_tool(tool_name: str, tool_args: Dict[str, Any]) -> str:
    """
    æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨ã€‚
    æ¥æ”¶å‡½æ•°åå’Œå‚æ•°å­—å…¸ï¼Œè¿”å› JSON å­—ç¬¦ä¸²ç»“æœã€‚
    """

    # 1. æŸ¥æ‰¾å·¥å…·
    if tool_name not in AVAILABLE_TOOLS:
        error_msg = f"æ‰§è¡Œå¤±è´¥: æ‰¾ä¸åˆ°å·¥å…· '{tool_name}'"
        print(f"âŒ {error_msg}")
        return json.dumps({"error": error_msg}, ensure_ascii=False)

    tool_function = AVAILABLE_TOOLS[tool_name]

    try:
        # 2. æ‰§è¡Œå·¥å…·
        # ä½¿ç”¨ ** è§£åŒ…å­—å…¸å‚æ•°ä¼ å…¥å‡½æ•°
        print(f"âš™ï¸ æ­£åœ¨è°ƒç”¨: {tool_name}({tool_args})")
        result = tool_function(**tool_args)

        # 3. ç»Ÿä¸€è¿”å›å€¼æ ¼å¼
        # LLM éœ€è¦æ¥æ”¶ String ç±»å‹çš„ contentã€‚
        # å¦‚æœå·¥å…·è¿”å›çš„æ˜¯å­—å…¸ã€åˆ—è¡¨ç­‰å¯¹è±¡ï¼Œå¿…é¡»è½¬ä¸º JSON å­—ç¬¦ä¸²ã€‚
        if isinstance(result, (dict, list, int, float, bool)):
            return json.dumps(result, ensure_ascii=False)

        # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ JSON å­—ç¬¦ä¸²ï¼‰ï¼Œç›´æ¥è¿”å›
        return str(result)

    except TypeError as e:
        # æ•æ‰å‚æ•°é”™è¯¯ï¼ˆä¾‹å¦‚æ¨¡å‹å¹»è§‰ç”Ÿæˆäº†ä¸å­˜åœ¨çš„å‚æ•°ï¼‰
        error_msg = f"å‚æ•°é”™è¯¯: å·¥å…· '{tool_name}' ä¸æ¥å—æä¾›çš„å‚æ•°: {e}"
        print(f"âŒ {error_msg}")
        return json.dumps({"error": error_msg}, ensure_ascii=False)

    except Exception as e:
        # æ•æ‰å·¥å…·å†…éƒ¨è¿è¡Œæ—¶çš„å…¶ä»–å¼‚å¸¸# æ‰“å°å †æ ˆä¿¡æ¯æ–¹ä¾¿è°ƒè¯•
        error_msg = f"è¿è¡Œæ—¶é”™è¯¯: å·¥å…· '{tool_name}' æ‰§è¡Œå¼‚å¸¸: {str(e)}"
        return json.dumps({"error": error_msg}, ensure_ascii=False)


def chat_with_context(user_input):
    """
    æ”¯æŒè¿ç»­å·¥å…·è°ƒç”¨çš„ä¸»å¯¹è¯é€»è¾‘
    """
    # 1. å‡†å¤‡åˆå§‹ä¸Šä¸‹æ–‡
    # æ³¨æ„ï¼šload_context è¿”å›çš„é€šå¸¸æ˜¯å†å²è®°å½•åˆ—è¡¨
    history = load_context()

    # æ„å»ºå½“å‰ä¼šè¯çš„æ¶ˆæ¯åˆ—è¡¨
    messages = []
    messages.append({'role': 'system', 'content': SYSTEM_PROMPT})
    messages.extend(history) # æ·»åŠ å†å²è®°å½•
    messages.append({'role': 'user', 'content': user_input})

    # ä¿å­˜ç”¨æˆ·è¾“å…¥åˆ°æ•°æ®åº“
    save_message('user', user_input)

    print(f"\nğŸ‘¤ ä½ : {user_input}\n")

    # è®¾ç½®æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œé˜²æ­¢æ­»å¾ªç¯ (ä¾‹å¦‚æ¨¡å‹ä¸æ–­æŠ¥é”™ä¸æ–­é‡è¯•)
    MAX_ITERATIONS = 5
    iteration = 0

    while iteration < MAX_ITERATIONS:
        print("ğŸ¤– Agent æ€è€ƒä¸­...")

        # 2. è°ƒç”¨ Ollama
        response = ollama.chat(
            model=MODEL_NAME,
            messages=messages,
            stream=False,
        )

        response_message = response['message']

        # å°†æ¨¡å‹çš„å›å¤æ·»åŠ åˆ°æ¶ˆæ¯å†å²ä¸­ (æ— è®ºæ˜¯æ–‡æœ¬è¿˜æ˜¯å·¥å…·è°ƒç”¨ï¼Œéƒ½å¿…é¡»åŠ è¿›å»ï¼Œå¦åˆ™æ¨¡å‹ä¼šå¿˜è®°å®ƒåˆšæ‰åšäº†ä»€ä¹ˆ)
        messages.append(response_message)

        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if response_message.get('tool_calls'):
            # è·å–åŸå§‹å¯¹è±¡åˆ—è¡¨
            raw_tool_calls = response_message['tool_calls']

            # ==================== æ ¸å¿ƒä¿®å¤å¼€å§‹ ====================
            # å°† ToolCall å¯¹è±¡åˆ—è¡¨è½¬æ¢ä¸ºæ™®é€šçš„å­—å…¸åˆ—è¡¨ (Dict List)
            # è¿™æ ·æ—¢å¯ä»¥é€šè¿‡ json.dumps ä¿å­˜ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ ['key'] ä¸‹æ ‡è®¿é—®
            tool_calls_serializable = []

            for tool in raw_tool_calls:
                if isinstance(tool, dict):
                    # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥æ·»åŠ 
                    tool_calls_serializable.append(tool)
                elif hasattr(tool, 'model_dump'):
                    # Ollama (Pydantic v2) é€šå¸¸æœ‰ model_dump æ–¹æ³•
                    tool_calls_serializable.append(tool.model_dump())
                elif hasattr(tool, 'dict'):
                    # æ—§ç‰ˆæœ¬ Pydantic å¯èƒ½ç”¨ .dict()
                    tool_calls_serializable.append(tool.dict())
                else:
                    # å¦‚æœä»¥ä¸Šéƒ½æ²¡æœ‰ï¼Œæ‰‹åŠ¨æå–å±æ€§
                    tool_calls_serializable.append({
                        'function': {
                            'name': tool.function.name,
                            'arguments': tool.function.arguments
                        },
                        'type': 'function'
                    })
            # ==================== æ ¸å¿ƒä¿®å¤ç»“æŸ ====================

            # 1. ä¿å­˜åˆ°æ•°æ®åº“ (ç°åœ¨ä¼ å…¥çš„æ˜¯å­—å…¸åˆ—è¡¨ï¼ŒJSON åºåˆ—åŒ–ä¸ä¼šæŠ¥é”™äº†)
            save_message('assistant', json.dumps(tool_calls_serializable, ensure_ascii=False))

            print(f"Agent: **éœ€è¦è°ƒç”¨ {len(tool_calls_serializable)} ä¸ªå·¥å…·**ï¼Œæ­£åœ¨æ‰§è¡Œ...")

            # 2. éå†æ‰§è¡Œ (æ³¨æ„ï¼šè¿™é‡Œéå†æˆ‘ä»¬è¦ç”¨è½¬æ¢åçš„ tool_calls_serializable)
            for tool in tool_calls_serializable:
                # å› ä¸ºæˆ‘ä»¬å·²ç»è½¬æˆäº†å­—å…¸ï¼Œæ‰€ä»¥è¿™é‡Œå¯ä»¥ç”¨ ['key'] è®¿é—®ï¼Œä¸ä¼šæŠ¥é”™
                function_name = tool['function']['name']
                function_args = tool['function']['arguments']

                logger.info(f"æ­£åœ¨æ‰§è¡Œå·¥å…·: {function_name} å‚æ•°: {function_args}")
                try:
                    tool_output = execute_single_tool(function_name,function_args)

                except Exception as e:
                    tool_output = f"Tool execution error: {str(e)}"

                # 4. å°†å·¥å…·æ‰§è¡Œç»“æœä½œä¸º 'tool' è§’è‰²æ¶ˆæ¯æ·»åŠ å›å»
                tool_message = {
                    'role': 'tool',
                    'content': str(tool_output),
                    # æŸäº› API å¯èƒ½éœ€è¦ tool_call_idï¼ŒOllama ç›®å‰ä¸»è¦ä¾èµ–é¡ºåºï¼Œä½†åŠ ä¸Šæ›´ç¨³å¦¥
                    # 'name': function_name
                }
                messages.append(tool_message)

                # åŒæ—¶ä¹Ÿä¿å­˜å·¥å…·ç»“æœåˆ°æ•°æ®åº“ï¼Œä»¥ä¾¿æœªæ¥ä¸Šä¸‹æ–‡ä½¿ç”¨
                save_message('tool', str(tool_output))

            # å¾ªç¯ç»§ç»­ï¼šå¸¦ç€å·¥å…·ç»“æœå›åˆ°å¼€å¤´ï¼Œå†æ¬¡è°ƒç”¨ ollama.chat
            iteration += 1
            logger.info(f"å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œè¿›å…¥ç¬¬ {iteration} è½®æ€è€ƒ...")

        else:
            # 5. æ²¡æœ‰å·¥å…·è°ƒç”¨ -> æœ€ç»ˆå›å¤
            final_content = response_message.get('content', '').strip()

            if not final_content:
                final_content = "ä»»åŠ¡å·²å®Œæˆï¼Œä½†æˆ‘æ²¡æœ‰æ›´å¤šå†…å®¹è¦è¡¥å……ã€‚"

            print("\n   Agent æœ€ç»ˆå›å¤: ")
            print(final_content)
            print("\n" + "-" * 30 + "\n")

            # ä¿å­˜æœ€ç»ˆå›å¤
            save_message('assistant', final_content)

            # ä»»åŠ¡ç»“æŸï¼Œè·³å‡ºå¾ªç¯
            return

    # å¦‚æœå¾ªç¯æ¬¡æ•°ç”¨å°½
    print("âš ï¸ è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ•°é™åˆ¶ï¼Œåœæ­¢æ‰§è¡Œã€‚")
'''
def chat_with_context(user_input): # ä¸»å¯¹è¯é€»è¾‘
    # 1. å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨ (åŒ…å«ç³»ç»Ÿæç¤ºå’Œå†å²è®°å½•)
    context_messages = load_context()# åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    context_messages.insert(0, {'role': 'system', 'content': SYSTEM_PROMPT})
    context_messages.append({'role': 'user', 'content': user_input})

    save_message('user', user_input) # å°†æœ€æ–°çš„ç”¨æˆ·è¾“å…¥ä¿å­˜åˆ°æ•°æ®åº“

    # 2. åˆå§‹ Ollama è°ƒç”¨
    print(f"\nğŸ‘¤ ä½ : {user_input}\n")
    print("ğŸ¤– Agent å¤„ç†ä¸­...")


    # LLM å“åº”çš„ç¬¬ä¸€éƒ¨åˆ†
    response = ollama.chat(
        model=MODEL_NAME,
        messages=context_messages,
        stream=False,
    )

    message = response['message']

    # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
    # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls å­—æ®µï¼Œä¸”å®ƒæ˜¯ä¸€ä¸ªéç©ºçš„åˆ—è¡¨
    if 'tool_calls' in message and isinstance(message['tool_calls'], list) and message['tool_calls']:

        tool_call_list = message['tool_calls']

        # æå–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
        first_tool_call = tool_call_list[0]
        tool_function = first_tool_call['function']

        tool_name = tool_function['name']
        tool_args = tool_function['arguments']

        # æ„å»º JSON å­—ç¬¦ä¸²ç”¨äºæ•°æ®åº“å’Œ LLM çš„ç¬¬äºŒæ¬¡è°ƒç”¨
        tool_call_data = {"tool": tool_name, "arguments": tool_args}
        tool_call_json = json.dumps(tool_call_data)

        # 3. å·¥å…·æ‰§è¡Œé€»è¾‘
        print(f"Agent: **å·²è¯†åˆ«åˆ°å·¥å…·è°ƒç”¨**ï¼Œæ­£åœ¨æ‰§è¡Œ...")
        save_message('assistant', tool_call_json)
        logger.info(f"LLM è¯†åˆ«ä¸ºå·¥å…·è°ƒç”¨ï¼Œæ­£åœ¨æ‰§è¡Œï¼š{tool_call_json[:100]}...")

        tool_output = execute_single_tool(message.tool_calls)

        # 4. ç¬¬äºŒæ¬¡ Ollama è°ƒç”¨ (å¸¦ç€å·¥å…·ç»“æœ)
        logger.info("è¿›è¡Œç¬¬äºŒæ¬¡ LLM è°ƒç”¨ (å¸¦å·¥å…·ç»“æœ) ä»¥è·å–æœ€ç»ˆå›å¤...")

        # 4a. å‡†å¤‡ç¬¬äºŒæ¬¡è°ƒç”¨çš„æ¶ˆæ¯åˆ—è¡¨ (ä¿æŒä¸å˜)
        second_call_messages = [{'role': 'system', 'content': SYSTEM_PROMPT}] + context_messages.copy()
        second_call_messages.append({'role': 'user', 'content': user_input})
        second_call_messages.append({'role': 'assistant', 'content': tool_call_json})
        second_call_messages.append({'role': 'tool', 'content': tool_output})

        # 4b. ç¬¬äºŒæ¬¡ Ollama è°ƒç”¨
        final_response = ollama.chat(
            model=MODEL_NAME,
            messages=second_call_messages,
            stream=False
        )

        # 4c. æå–æœ€ç»ˆå“åº”
        final_answer = final_response.message.content.strip()

        print("\n   Agent æœ€ç»ˆå›å¤: ")
        print(final_answer)  # ç›´æ¥æ‰“å°å®Œæ•´å›å¤

        print("\n" + "-" * 30 + "\n")
    else:

        # æå– content å­—æ®µä½œä¸ºæœ€ç»ˆå›å¤
        full_response_content = message.get('content', '').strip()

        if not full_response_content:
            # å¦‚æœæ¨¡å‹æ²¡æœ‰è¿”å› contentï¼Œä½†ä¹Ÿæ²¡æœ‰ tool_callsï¼Œå¯èƒ½æ˜¯é—²èŠæ¨¡å¼çš„æ€è€ƒè¿‡ç¨‹
            full_response_content = "æˆ‘æ²¡æœ‰æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„å·¥å…·ï¼Œè¯·æ˜ç¡®æ‚¨çš„é—®é¢˜ã€‚"

        # 3. ç›´æ¥å›å¤
        print(" Agent æœ€ç»ˆå›å¤: ")
        print(full_response_content)
        print("\n" + "-" * 30 + "\n")

        # 4. ä¿å­˜ç¬¬ä¸€ä¸ªå“åº”
        save_message('assistant', full_response_content)
'''
# ä¸»å¾ªç¯
def interactive_chat():
    init_db()

    while True:
        try:
            user_input = input("è¯·è¾“å…¥ä½ çš„é‡‘èé—®é¢˜ (è¾“å…¥ 'exit' é€€å‡º, 'clear' æ¸…ç©ºå†å²): \n> ")
        except EOFError:
            break

        if user_input.lower() == 'exit':
            break

        if user_input.lower() == 'clear':
            conn = sqlite3.connect(DB_NAME)
            conn.execute("DELETE FROM conversation")
            conn.commit()
            conn.close()
            logger.info("å¯¹è¯å†å²å·²æ¸…ç©ºï¼")
            continue

        if user_input.strip():
            chat_with_context(user_input)

    logger.info("é‡‘è AI Agent å·²é€€å‡ºã€‚")


if __name__ == '__main__':
    clear_screen()
    interactive_chat()
    # åŠ è½½å¹¶æ˜¾ç¤ºå†å²æ¦‚è¦
    history = load_context()
    if history:
        print(f"--- å†å²è®°å½• ({len(history)} æ¡æ¶ˆæ¯) ---")
        last_user_msg = next((m['content'] for m in reversed(history) if m['role'] == 'user'), "æ— ")
        print(f"æœ€è¿‘ç”¨æˆ·: {last_user_msg[:50]}...")
        print("-" * 30)
    else:
        print("--- å¼€å§‹æ–°å¯¹è¯ ---")